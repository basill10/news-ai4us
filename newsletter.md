Title: Anthropic climbs AI ranks with Claude Opus 4.5

At a Glance: 

Anthropic just released Claude Opus 4.5, the company’s new flagship model that competes with Gemini 3 and GPT-5.1 for top performance across the board, particularly excelling on coding and agentic benchmarks.

The details:

Opus is the first to break 80% on the SWE-Bench Verified coding benchmark, also setting new highs for tool use, reasoning, and problem-solving.

The model matches or beats Google’s Gemini 3 across a range of benchmarks, with Anthropic also calling it the “most robustly aligned model” safety-wise.

Anthropic designed Opus to orchestrate teams of smaller Haiku models, positioning the flagship model as a central coordinator for multi-agent systems.

Opus 4.5’s pricing also notably comes in at a 66% reduction from Opus 4.1, while also showing massive efficiency gains over Anthropic’s other models.

Anthropic also rolled out updates, including unlimited chat lengths, Claude Code in desktop, and expanded access to Claude for Chrome & Excel.

Why it matters: 

Opus 4.5 arrives in a packed week for frontier AI, landing just days after GPT 5.1 Pro and Gemini 3 hit the market and marking the next step up in the frontier AI model race. The price reduction is also a big move for Anthropic, which has often been criticized for Claude’s costs compared to the market.



