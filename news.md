1. a mind-blowing photo editing AI a new open source sandbox and of course a conversation about whether openai is seeking regulatory capture what's going on guys welcome back to the AI breakdown this is the weekly recap where I talk about some of the most important news that happened this week we start with a really mind-blowing new photo editing tool that's in the research stage and basically this video started exploding all over Twitter on Friday morning for people who are listening you're seeing images that someone is clicking on a particular part so it could be the face of a lion or it could be the face of a dog and actually manipulating them simply by dragging them it's photorealistic image manipulation all through AI billowalsid who writes whoa this new AI paper is legit like Adobe puppet warp on steroids text prompts aren't the be-all end-all of AI creation drag Gan is a perfect example of giving creators fine-grained control over the AI image generation process draggan allows you to reshape images interactively much like pulling on points in the image to move them exactly where you want the system relies on two main parts one that guides the point you're moving the handle Point towards its destination and the other that keeps track of the handle Point's position using features specific to the underlying technology Gans dragan is super flexible you can tweak various aspects of your images such as pose shape and expression it works on a wide range of subjects including animals cars peoples Landscapes Etc now in an example of using AI to understand AI I went to Chachi BT and took advantage of a new plugin called X papers I asked chatgpt do you have access to this paper and it said yes I have access to the paper you're asking about it's called drag your Gan interactive point-based manipulation on the generative image manifold I said can you please summarize the paper for an audience at a high school graduate level in no more than five bullets making sure to explain both generative adversarial networks and dragon chat TPT did exactly that generative adversarial networks or Gans are a type of artificial intelligence model that can create new data that resembles the original data it was trained on imagine it has two artists the generator and the discriminator competing against each other the generator tries to create convincing fake paintings while the discriminator tries to tell if the paintings are real or fake over time both get better the generator at creating fakes and the discriminator at spotting them number two the problem when we use Gans to create images we often want to control specific details like the poser shape of an object in the image but existing methods to control Gans aren't very flexible or precise dragan is the solution this is a new process that allows users to drag points on an image to change it in specific ways for example changing the pose of a person now importantly I was also able to ask can it be used to modify real world images or is it only useful for images that have been created with AI chatgpt says dragon can indeed be used to modify real world images but it requires an additional step this step is called Gan inversion again inversion is a process where a real world image is transferred into the latent space of the Gan so while dragan is primarily designed to work with images generated by again it can also be used with real world images through the process of Gan inversion pretty wild stuff all around speaking of pretty wild this is a demo from blockade Labs of their new Skybox tool which allows you to effectively sketch a 3D world that you'd like to see and give it a little bit of a description and then have it appear exactly as you'd imagined I am seeing such an explosion of 3D World building tools I am really really excited to see what comes out of it from the standpoint of games and metaverse and applications we can't even imagine yet now one other product release that I thought was really interesting was stability AI announcing stable Studio stability AI is of course the company behind stable diffusion and you might have used their tool dream Studio which is their main web-based interface for interacting with their text to image tools stable studio is effectively an open source version of dream Studio that encourages people to actually build out these tools in an open source way at the heart of it is their AI image generator but they're also bringing in all of their other open source tools as well including their language model stable LM as well as soon their stable vacuna chat interface for stable in the stable Studio press release the company wrote We believe the best way to expand is through open Community Driven development rather than private iteration on a closed Source product the end goal they say is to create an AI interface for users to quote fully control now stability AI will continue to build out dream Studio but that will effectively be their own internal implementation of dream Studio which anyone can now build upon the open source discourse also got a boost from a big New York Times article this week that focused in on meta and young lacun lacun who is the chief AI scientist at meta wrote on Twitter a New York Times article on the debate around whether llm base models should be closed or open meta argues for openness starting with the release of llama for non-commercial use while openai and Google want to keep things closed and proprietary they argue that openness can be dangerous but they are just protecting their commercial interests I argue that closeness is considerably more dangerous than openness once llms become the main Channel through which everyone accesses information people and governments will demand that it be open and transparent basic infrastructure must be open now this is all the more interesting in light of the Senate hearing on AI earlier this week leading into that disability AI had written a letter to Senators advocating something pretty similar the letter goes into some detail about the importance of open models but is summed up in a quote from Imam the CEO of stability he writes these technologies will be the backbone of our digital economy and it is essential that the public can scrutinize their development open models and open data sets will help to improve safety through transparency Foster competition and ensure the United States retains strategic leadership in critical AI capabilities Grassroots Innovation is America's greatest asset and open models will help put these tools in the hands of workers and firms across the country I did an entire show about the hearing but one of the notable features of it was that whereas there's often a lot of acrimony between senators or congress people and their Witnesses particularly if those Witnesses come from Big tech companies that didn't seem to be on display in this particular case part of that seems to have been the fact that the witness that they were most interested in talking to which was undoubtedly Sam Altman the CEO of openai seemed to be broadly in agreement with them that there needed to be a new regulatory apparatus for AI going so far as to even say that he would support AI licenses here's Senator Lindsey Graham in a key section of that hearing Mr Allman why are you so willing to have an agency Senator we've been clear about what we think the upsides are and I think you can see from users how much they enjoyed how much value they're getting out of it but we've also been clear about what the downsides are and so that's why we think it's just a it's a major tool to be used by a lot it's a major new technology yeah if you make a ladder and the ladder doesn't work you ensue the people made the letter but there are some standards out there to make a letter so that's why we're agreeing with you yeah that's right I think you're on the right track so here's what my two cents worth for the committee is that we need to empower an agency that issues in a license and can take it away wouldn't that be some incentive to do it right if you could actually be taken out of business clearly that should be part of what an agency can do now to get a sense of how many people reacted to this part of Sam's testimony just look at gphoder.id on Twitter who wrote Sam proposing licenses for AI training is the most awful thing I've ever heard him say how disappointing Say It Ain't So Antonio Garcia Martinez writes I love how quickly we went from a promising prototype to hysterical clout chasing opportunists issuing dire warnings to Craven corporate regulatory capture in the span of months and indeed this theme of regulatory capture was a huge one Scott Galloway says we're falling for this again Altman CEO of openai calls for U.S to regulate artificial intelligence Brad hateman responded summing up what Galloway was trying to say writing Tech execs say we need more regulations Tech execs think bigger moats equal bigger rents denying Sam's sincerity and his beliefs of the risks of AI at J River long who has the effective acceleration as tag in his profile said Sam Altman going in front of Congress to demand AI regulation and disclosure is regulatory capture plain and simple he thinks he has the business of the century and wants to ban competition Sam is dangerous and the AI safety crowd are you useful idiots to his monopolist goals now not everyone thought this way Matthew Barnett for example writes I think regulatory capture explanations are overrated Sam Altman presumably wants to be seen as a responsible CEO while minimizing the impact of regulations on open AI this Theory explains our observations just as well if this all got loud enough that Sam decided that he wanted to respond former open AI or alithia power tweeted a clip of Sam and said I think people talking about regulatory capture missed the part where Sam said that regulation should be stricter on orgs that are training larger models with more compute like open AI while remaining flexible enough for startups and independent researchers to flourish Sam himself quote tweeted that and said regulation should take effect above a capability threshold a GI safety is really important and Frontier models should be regulated regulatory capture is bad and we shouldn't mess with models below the threshold open source models and small startups are obviously important so I think there are three possibilities here one is that Sam's being sincere he's not trying to use regulatory capture as a strategy he's not hoping that onerous or burdensome regulations will crowd out competitors because they don't have the resources to comply he is just genuinely worried about what could happen if AI isn't regulated at all a second possibility is that he is going for regulatory capture for what he views as good reasons as in he genuinely believes that there could be harm and he wants only a small number of companies including his to be able to actually have the power to cause that harm or not a third possibility is regulatory capture for bad reasons as in he's insincere about these concerns and he just wants to position open AI to be the leader of the next wave in a lot of ways I don't think it particularly matters in that I don't think we should be making decisions about policies in terms of what Sam does or doesn't want or what he does or doesn't think we need to consider the issues of regulatory capture carefully whether Sam intends for open AI to be a beneficiary of them or not regulations do increase the cost of compliance they do create modes for incumbents and there's a very real chance that we prohibit or license the wrong thing especially especially with such a frontier technology there are real reasons to be concerned about that at the same time outside of any consideration of open AI there are good reasons to have this conversation about whether we should have guard rails and what they should be I think it's clear that what needs to happen next is specificity in the conversation right now we're speaking in super vague generalities and that's creating a scenario where people are mapping on their priors and their expectations and their beliefs about people without actually engaging with specific policy proposals which makes sense because they don't exist yet so for now I'm reserving my judgment because like I said I think the conversation is important regardless of whatever Sam or open AI think and I think it's the right conversation to be having right now anyways guys if you ask me that is a very characteristic week in AI right now on the one end of the spectrum some mind-blowing tools that you couldn't have imagined just about five minutes ago and on the other end of the questions big existential questions that could change the shape of public institutions if you're enjoying the AI breakdown please like subscribe and share go follow the podcast and follow the newsletter and as always I appreciate you listening and watching until next next time peace

2. CLOSELY, RAISING ALARM BELLS.
   NBC'S ERIN MCLAUGHLIN TRIED IT OUT.
   > > THIS IS YOUR NEW CREATIVE PARTNER.
   > > BUT SHOULD IT BE? WITH THE LAUNCH OF GOOGLE'S LATEST AI IMAGE GENERATION AND EDITING TOOL, THE NEW AND IMPROVED NANO BANANA PRO.
   > > IN VIVID 4K.
   > > ANYONE CAN CREATE VISUALS SO LIFELIKE. EXPERTS ARE SOUNDING THE ALARM.
   > > YOU WILL BE FOOLED BY AN AI PHOTO THIS WEEK, AND YOU PROBABLY ALREADY HAVE BEEN, AND YOU DIDN'T KNOW IT.
   > > CONTENT CREATOR JEREMY CARRASCO, WHO TEACHES HIS FOLLOWERS HOW TO SPOT FAKE AI CONTENT, WARNS THIS LATEST ADVANCE IS MAKING THE FAKES HARDER TO PICK OUT.
   > > IT IS A STEP UP IN REALISM SPECIFICALLY, SO A LOT OF THE THINGS THAT WE USED TO LOOK FOR, SUCH AS A BLURRY CAMERA IMAGE OR SOMETHING THAT JUST LOOKED A LITTLE BIT TOO GLOSSY OR A LITTLE BIT TOO SMOOTH, A LOT OF THAT HAS BEEN STRAIGHTENED OUT.
   > > GIVEN THIS NEW TECHNOLOGY.
   > > ANYTIME ANYONE SEES AN IMAGE ONLINE, THEIR FIRST REACTION SHOULD BE IS THIS REAL?
   > > ESPECIALLY IF IT IS SENSATIONAL, STRANGE, OR A BIT TOO GOOD TO BE TRUE. THAT SHOULD ABSOLUTELY BE THE DEFAULT.
   > > WE TESTED NANO BANANA PRO FOR OURSELVES, GENERATING REALISTIC IMAGES WITH THE STROKE OF A KEYBOARD. WE'RE ASKING IT TO CREATE AN IMAGE OF THE CHRISTMAS TREE OUTSIDE OF 30 ROCK. OH WOW, THAT LOOKS PRETTY REALISTIC. ALL RIGHT, LET'S ESCALATE THE SITUATION. I WANT TO SEE A GIANT POLAR BEAR ATTACK THE TREE. LET'S SEE WHAT IT DOES. NOW COMPARE THAT TO THE IMAGE GENERATED BY CHATGPT NANO BANANA PRO ALSO ALLOWS YOU TO UPLOAD AN IMAGE OF YOURSELF.
   > > LET'S SEE WHAT IT DOES AND ASK IT TO PLACE YOU IN SOME PRETTY EXTRAORDINARY SITUATIONS. TAKE ME TO MARS AS AN ASTRONAUT. THE CHATGPT VERSION CREATED FROM THE SAME PROMPT IS LESS DETAILED. I LOOK VERY HAPPY FOR SOMEONE WHO'S JUST TRAVELED AND ARRIVED ON MARS WITHIN SECONDS.
   > > NANO BANANA PRO GENERATED REALISTIC IMAGES OF EVERYONE FROM THE PRESIDENT TO AL ROKER.
   > > PART OF THE REASON EXPERTS SAY THEY'RE SO CONCERNED IS THIS DANGEROUS?
   > > ABSOLUTELY.
   > > WHEN WE ASKED ABOUT THE CONCERN, GOOGLE POINTED US TO THEIR GENERATIVE AI USE POLICY, WHICH PROHIBITS IMPERSONATING AN INDIVIDUAL IN ORDER TO DECEIVE. ADDING EACH IMAGE INCLUDES A VISIBLE WATERMARK.
   > > I THINK THAT GOOGLE'S IDEA OF RELEASING THIS WITHOUT GUARDRAILS AGAINST PUBLIC FIGURES IS A VERY BIG ESCALATION, AND LACK OF AI SAFETY, SO THAT'S A BIG STEP IN THE WRONG DIRECTION.
   > > EACH IMAGE INCLUDES A WATERMARK ON THE LOWER RIGHT HAND SIDE, AND SOMETHING GOOGLE CALLS SYNTH ID, AN IMPERCEPTIBLE WATERMARK WOVEN INTO THE IMAGE'S PIXELS. AND LET'S TALK ABOUT THE WATERMARK.
   > > YOU CAN SEE IT RIGHT DOWN HERE ON THE LOWER RIGHT HAND SIDE OF THE IMAGE. IT WOULD BE SO EASY TO CROP THAT OUT. STILL, CRITICS LIKE CARRASCO SAY THAT'S NOT ENOUGH.
   > > I THINK THAT THERE SHOULD BE SOME EXPECTATION THAT THEY PULL THAT BACK. WE HAVE TO DEMAND THEY DO, BECAUSE JUST THE IDEA OF ANYONE BEING ABLEO ESSENTIALLY BECOME A PHOTOSHOP PRO OVERNIGHT AND USE THESE CELEBRITIES OR THESE POLITICIANS LIKENESS IS OBVIOUSLY A VERY FRIGHTENING THING.
   > > ALL RIGHT. ERIN MCLAUGHLIN JOINS US NOW. IT'S FUN TO SAY NANO BANANA. YOU HAVE TO PAY TO GET THE FULL FEATURES. IT'S NOT FREE.
   > > YEAH. THE FIRST FEW IMAGES ARE FREE. AND THEN AFTER THAT YOU NEED A SUBSCRIPTION. AND THEN BEYOND THAT, YOU KNOW, THE REAL SORT OF USE CASE REPRESENTATIVE FROM GOOGLE WAS TELLING US IS THE BUSINESS USE CASE A REALLY FOCUSED ON ENTERPRISE SOFTWARE, SPECIFICALLY MARKETING AND ADVERTISING, A WHOLE SECTOR OF THE ECONOMY THAT COULD BE COMPLETELY REVOLUTIONIZED BY THIS TECHNOLOGY.
   > > WE'VE SEEN GOOGLE STOCK CLIMB THE LAST COUPLE OF WEEKS HERE SINCE THIS LAUNCH. IS THIS GOING TO PUT EVEN MORE PRESSURE ON THE COMPETITORS LIKE CHATGPT, OPENAI?
   > > YEAH, EXPERTS TELL US, WITHOUT A DOUBT. ESSENTIALLY, THIS IS GOING TO CONTINUE. THE AR AI ARMS RACE THAT'S ALREADY AT PLAY, PUTTING PRESSURE ON ITS COMPETITORS SUCH AS OPENAI TO FOLLOW SUIT WITH THEIR IMPROVING ON THEIR OWN IMAGE GENERATION TECHNOLOGY, AND THEN BEYOND THAT, POTENTIALLY PUT PRESSURE ON THE SOCIAL MEDIA PLATFORMS THEMSELVES. THINGS LIKE INSTAGRAM, TIKTOK. HOW ARE THEY GOING TO INTERACT WITH THIS CONTENT? ARE THEY GOING TO START FLAGGING AI GENERATED CONTENT?
   > > SO, ERIN, YOU MADE ALL OF THOSE IMAGES. DID YOU HAVE TO UPLOAD ANY IMAGES? LIKE, YOU KNOW, THE GUY WAS SAYING, THE GUARDRAILS HERE, THE IMAGES OF AL ROKER IMAGES OF YOU. THE COMPUTER DID EVERYTHING.
   > > THE IMAGES OF AL ROKER, THE IMAGE OF THE PRESIDENT. I JUST TYPED IN AL ROKER PRESIDENT TRUMP,
